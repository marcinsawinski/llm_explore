,summary,config,name,metadata,sys
0,"{'dev_test_recall': 0.637, 'train/train_loss': 0.29443022809245367, 'train/global_step': 1100, 'eval/rec': 0.8150470219435737, 'eval/f1_ma': 0.9036630633480772, 'dev_test_accuracy': 0.797, 'eval/loss': 0.310095876455307, 'test_recall': 0.731, 'eval/prec': 0.9219858156028368, '_timestamp': 1700122261.7759526, 'dev_test_precision': 0.937, '_wandb': {'runtime': 23040}, 'eval/acc': 0.919, 'test_precision': 0.919, 'eval/steps_per_second': 0.8, 'test_f1': 0.814, '_runtime': 23041.139828681946, 'train/loss': 0.0985, 'train/epoch': 1.14, 'eval/runtime': 156.3141, 'train/train_steps_per_second': 0.085, '_step': 228, 'eval/f1_bi': 0.8652246256239602, 'test_accuracy': 0.887, 'dev_test_f1': 0.758, 'train/train_runtime': 22680.5925, 'eval/samples_per_second': 6.397, 'train/train_samples_per_second': 0.678, 'train/total_flos': 1.312224774322176e+17, 'train/learning_rate': 4.298336798336799e-06}","{'bf16': False, 'fp16': True, 'fsdp': [], 'seed': 42, 'tf32': None, 'debug': [], 'optim': 'adamw_torch', 'top_k': 50, 'top_p': 1, 'prefix': None, 'do_eval': True, 'no_cuda': False, 'use_cpu': False, 'do_train': False, 'id2label': {'0': 'LABEL_0', '1': 'LABEL_1'}, 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'run_name': './output-trainer', 'use_ipex': False, 'adafactor': False, 'data_seed': None, 'deepspeed': None, 'do_sample': False, 'hub_token': '<HUB_TOKEN>', 'log_level': 'passive', 'max_steps': -1, 'num_beams': 1, 'ray_scope': 'last', 'report_to': ['wandb'], 'typical_p': 1, 'use_cache': True, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'do_predict': False, 'eval_delay': 0, 'eval_steps': 10, 'hidden_act': 'silu', 'is_decoder': False, 'local_rank': 0, 'max_length': 20, 'min_length': 0, 'model_type': 'llama', 'optim_args': None, 'output_dir': './output-trainer', 'past_index': -1, 'rope_theta': 10000, 'save_steps': 100, 'vocab_size': 32000, 'ddp_backend': None, 'ddp_timeout': 1800, 'fsdp_config': {'xla': False, 'min_num_params': 0, 'xla_fsdp_grad_ckpt': False}, 'hidden_size': 5120, 'label_names': None, 'logging_dir': './output-trainer/logs', 'push_to_hub': False, 'return_dict': True, 'temperature': 1, 'torch_dtype': 'float16', 'torchdynamo': None, 'torchscript': False, 'adam_epsilon': 1e-08, 'bos_token_id': 1, 'disable_tqdm': False, 'eos_token_id': 2, 'fp16_backend': 'auto', 'hub_model_id': None, 'hub_strategy': 'every_save', 'pad_token_id': 2, 'problem_type': None, 'pruned_heads': {}, 'rms_norm_eps': 1e-05, 'rope_scaling': None, 'sep_token_id': None, 'use_bfloat16': False, 'warmup_ratio': 0, 'warmup_steps': 0, 'weight_decay': 0.01, 'architectures': ['LlamaForCausalLM'], 'bad_words_ids': None, 'jit_mode_eval': False, 'learning_rate': 1e-05, 'logging_steps': 10, 'max_grad_norm': 1, 'mp_parameters': '', 'output_scores': False, 'save_strategy': 'steps', 'split_batches': False, 'torch_compile': False, 'tpu_num_cores': None, 'attention_bias': False, 'bf16_full_eval': False, 'early_stopping': False, 'fp16_full_eval': False, 'fp16_opt_level': 'O1', 'length_penalty': 1, 'pretraining_tp': 1, 'tf_legacy_loss': False, 'use_mps_device': False, 'finetuning_task': None, 'group_by_length': False, 'hub_always_push': False, 'num_beam_groups': 1, 'suppress_tokens': None, 'tokenizer_class': None, 'deepspeed_plugin': None, 'dispatch_batches': None, 'full_determinism': False, 'hub_private_repo': False, 'ignore_data_skip': False, 'log_on_each_node': True, 'logging_strategy': 'steps', 'num_train_epochs': 2, 'save_safetensors': True, 'save_total_limit': 12, 'ddp_bucket_cap_mb': None, 'distributed_state': 'Distributed environment: NO\nNum processes: 1\nProcess index: 0\nLocal process index: 0\nDevice: cuda\n', 'diversity_penalty': 0, 'greater_is_better': True, 'initializer_range': 0.02, 'intermediate_size': 13824, 'log_level_replica': 'warning', 'lr_scheduler_type': 'linear', 'num_hidden_layers': 40, 'output_attentions': False, 'push_to_hub_token': '<PUSH_TO_HUB_TOKEN>', 'save_on_each_node': False, 'tpu_metrics_debug': False, 'is_encoder_decoder': False, 'length_column_name': 'length', 'logging_first_step': False, 'repetition_penalty': 1, 'torch_compile_mode': None, 'add_cross_attention': False, 'evaluation_strategy': 'steps', 'forced_bos_token_id': None, 'forced_eos_token_id': None, 'fsdp_min_num_params': 0, 'neftune_noise_alpha': None, 'num_attention_heads': 40, 'num_key_value_heads': 40, 'quantization_config': {'load_in_4bit': True, 'load_in_8bit': False, 'quant_method': 'QuantizationMethod.BITS_AND_BYTES', 'llm_int8_threshold': 6, 'bnb_4bit_quant_type': 'nf4', 'llm_int8_skip_modules': None, 'bnb_4bit_compute_dtype': 'bfloat16', 'llm_int8_has_fp16_weight': False, 'bnb_4bit_use_double_quant': True, 'llm_int8_enable_fp32_cpu_offload': False}, 'skip_memory_metrics': True, 'tie_encoder_decoder': False, 'tie_word_embeddings': False, 'auto_find_batch_size': False, 'dataloader_drop_last': False, 'no_repeat_ngram_size': 0, 'num_return_sequences': 1, 'output_hidden_states': False, 'overwrite_output_dir': True, 'prediction_loss_only': False, 'push_to_hub_model_id': None, 'task_specific_params': None, 'transformers_version': '4.35.0', 'begin_suppress_tokens': None, 'dataloader_pin_memory': True, 'ddp_broadcast_buffers': None, 'metric_for_best_model': 'f1_bi', 'remove_invalid_values': False, 'remove_unused_columns': True, 'torch_compile_backend': None, 'dataloader_num_workers': 0, 'decoder_start_token_id': None, 'gradient_checkpointing': False, 'half_precision_backend': 'auto', 'label_smoothing_factor': 0, 'load_best_model_at_end': True, 'logging_nan_inf_filter': True, 'resume_from_checkpoint': None, 'chunk_size_feed_forward': 0, 'eval_accumulation_steps': None, 'max_position_embeddings': 4096, 'per_gpu_eval_batch_size': None, 'return_dict_in_generate': False, 'per_gpu_train_batch_size': None, 'push_to_hub_organization': None, 'include_tokens_per_second': False, 'ddp_find_unused_parameters': None, 'include_inputs_for_metrics': False, 'per_device_eval_batch_size': 8, 'use_legacy_prediction_loop': False, 'cross_attention_hidden_size': None, 'gradient_accumulation_steps': 1, 'per_device_train_batch_size': 8, 'encoder_no_repeat_ngram_size': 0, 'gradient_checkpointing_kwargs': None, 'exponential_decay_length_penalty': None, 'fsdp_transformer_layer_cls_to_wrap': None}",llama13|adamw_torch 8 1e-05 f1_bi 2|r21|0,"{'os': 'Linux-5.10.0-21-amd64-x86_64-with-glibc2.29', 'python': '3.8.10', 'heartbeatAt': '2023-11-16T01:47:01.388901', 'startedAt': '2023-11-16T01:47:00.633252', 'docker': None, 'cuda': None, 'args': ['-n', '2'], 'state': 'running', 'program': 'cp_train_template_llama.py', 'codePath': 'cp_train_template_llama.py', 'git': {'remote': 'https://github.com/marcinsawinski/clef23_eval.git', 'commit': '5ee747d1ef67d6aecf42314b8cd247d6f91ddd0c'}, 'email': 'marcin.sawinski@gmail.com', 'root': '/root/notebooks/msawinski/clef23_eval', 'host': 'c301b88b57d6', 'username': 'root', 'executable': '/usr/bin/python', 'cpu_count': 10, 'cpu_count_logical': 20, 'cpu_freq': {'current': 1207.8581999999997, 'min': 1200.0, 'max': 4420.0}, 'cpu_freq_per_core': [{'current': 1200.118, 'min': 1200.0, 'max': 4400.0}, {'current': 1200.204, 'min': 1200.0, 'max': 4400.0}, {'current': 1200.93, 'min': 1200.0, 'max': 4400.0}, {'current': 1200.228, 'min': 1200.0, 'max': 4400.0}, {'current': 1200.431, 'min': 1200.0, 'max': 4400.0}, {'current': 1200.328, 'min': 1200.0, 'max': 4400.0}, {'current': 1200.228, 'min': 1200.0, 'max': 4400.0}, {'current': 1200.571, 'min': 1200.0, 'max': 4400.0}, {'current': 1200.0, 'min': 1200.0, 'max': 4500.0}, {'current': 1345.888, 'min': 1200.0, 'max': 4500.0}, {'current': 1200.121, 'min': 1200.0, 'max': 4400.0}, {'current': 1200.337, 'min': 1200.0, 'max': 4400.0}, {'current': 1200.334, 'min': 1200.0, 'max': 4400.0}, {'current': 1200.215, 'min': 1200.0, 'max': 4400.0}, {'current': 1200.166, 'min': 1200.0, 'max': 4400.0}, {'current': 1200.119, 'min': 1200.0, 'max': 4400.0}, {'current': 1200.286, 'min': 1200.0, 'max': 4400.0}, {'current': 1200.165, 'min': 1200.0, 'max': 4400.0}, {'current': 1215.217, 'min': 1200.0, 'max': 4500.0}, {'current': 1303.181, 'min': 1200.0, 'max': 4500.0}], 'disk': {'total': 1738.1651229858398, 'used': 1514.7118301391602}, 'gpu': 'NVIDIA GeForce RTX 2080 Ti', 'gpu_count': 4, 'gpu_devices': [{'name': 'NVIDIA GeForce RTX 2080 Ti', 'memory_total': 11811160064}, {'name': 'NVIDIA GeForce RTX 2080 Ti', 'memory_total': 11811160064}, {'name': 'NVIDIA GeForce RTX 2080 Ti', 'memory_total': 11811160064}, {'name': 'NVIDIA GeForce RTX 2080 Ti', 'memory_total': 11811160064}], 'memory': {'total': 93.98457717895508}}","{'allocatedmax': 41.0, 'allocatedmed': 40.0, 'allocatedgbmax': 19.14, 'allocatedgbmed': 18.89}"
1,"{'test_accuracy': 0.896, 'dev_test_recall': 0.694, 'train/total_flos': 9.51173983199232e+16, 'train/train_samples_per_second': 0.845, 'eval/acc': 0.916, 'test_precision': 0.912, 'train/train_loss': 0.35283432620076033, 'eval/samples_per_second': 11.445, '_runtime': 18419.35308623314, 'eval/rec': 0.8150470219435737, 'eval/f1_bi': 0.8609271523178809, 'eval/f1_ma': 0.9003776162735536, 'train/loss': 0.0345, '_wandb': {'runtime': 18418}, 'test_recall': 0.769, 'dev_test_precision': 0.925, 'eval/steps_per_second': 1.431, 'train/train_steps_per_second': 0.106, 'eval/loss': 0.3497604429721832, 'train/train_runtime': 18209.3552, '_timestamp': 1700099134.1849153, 'eval/runtime': 87.3775, 'dev_test_accuracy': 0.819, 'train/global_step': 1560, 'eval/prec': 0.912280701754386, 'dev_test_f1': 0.793, '_step': 320, 'train/epoch': 1.62, 'train/learning_rate': 1.917879417879418e-06, 'test_f1': 0.834}","{'bf16': False, 'fp16': True, 'fsdp': [], 'seed': 42, 'tf32': None, 'debug': [], 'optim': 'paged_adamw_8bit', 'top_k': 50, 'top_p': 1, 'prefix': None, 'do_eval': True, 'no_cuda': False, 'use_cpu': False, 'do_train': False, 'id2label': {'0': 'LABEL_0', '1': 'LABEL_1'}, 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'run_name': './output-trainer', 'use_ipex': False, 'adafactor': False, 'data_seed': None, 'deepspeed': None, 'do_sample': False, 'hub_token': '<HUB_TOKEN>', 'log_level': 'passive', 'max_steps': -1, 'num_beams': 1, 'ray_scope': 'last', 'report_to': ['wandb'], 'typical_p': 1, 'use_cache': True, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'do_predict': False, 'eval_delay': 0, 'eval_steps': 10, 'hidden_act': 'silu', 'is_decoder': False, 'local_rank': 0, 'max_length': 20, 'min_length': 0, 'model_type': 'llama', 'optim_args': None, 'output_dir': './output-trainer', 'past_index': -1, 'rope_theta': 10000, 'save_steps': 100, 'vocab_size': 32000, 'ddp_backend': None, 'ddp_timeout': 1800, 'fsdp_config': {'xla': False, 'min_num_params': 0, 'xla_fsdp_grad_ckpt': False}, 'hidden_size': 4096, 'label_names': None, 'logging_dir': './output-trainer/logs', 'push_to_hub': False, 'return_dict': True, 'temperature': 1, 'torch_dtype': 'float16', 'torchdynamo': None, 'torchscript': False, 'adam_epsilon': 1e-08, 'bos_token_id': 1, 'disable_tqdm': False, 'eos_token_id': 2, 'fp16_backend': 'auto', 'hub_model_id': None, 'hub_strategy': 'every_save', 'pad_token_id': 2, 'problem_type': None, 'pruned_heads': {}, 'rms_norm_eps': 1e-05, 'rope_scaling': None, 'sep_token_id': None, 'use_bfloat16': False, 'warmup_ratio': 0, 'warmup_steps': 0, 'weight_decay': 0.01, 'architectures': ['LlamaForCausalLM'], 'bad_words_ids': None, 'jit_mode_eval': False, 'learning_rate': 1e-05, 'logging_steps': 10, 'max_grad_norm': 1, 'mp_parameters': '', 'output_scores': False, 'save_strategy': 'steps', 'split_batches': False, 'torch_compile': False, 'tpu_num_cores': None, 'attention_bias': False, 'bf16_full_eval': False, 'early_stopping': False, 'fp16_full_eval': False, 'fp16_opt_level': 'O1', 'length_penalty': 1, 'pretraining_tp': 1, 'tf_legacy_loss': False, 'use_mps_device': False, 'finetuning_task': None, 'group_by_length': False, 'hub_always_push': False, 'num_beam_groups': 1, 'suppress_tokens': None, 'tokenizer_class': None, 'deepspeed_plugin': None, 'dispatch_batches': None, 'full_determinism': False, 'hub_private_repo': False, 'ignore_data_skip': False, 'log_on_each_node': True, 'logging_strategy': 'steps', 'num_train_epochs': 2, 'save_safetensors': True, 'save_total_limit': 12, 'ddp_bucket_cap_mb': None, 'distributed_state': 'Distributed environment: NO\nNum processes: 1\nProcess index: 0\nLocal process index: 0\nDevice: cuda\n', 'diversity_penalty': 0, 'greater_is_better': True, 'initializer_range': 0.02, 'intermediate_size': 11008, 'log_level_replica': 'warning', 'lr_scheduler_type': 'linear', 'num_hidden_layers': 32, 'output_attentions': False, 'push_to_hub_token': '<PUSH_TO_HUB_TOKEN>', 'save_on_each_node': False, 'tpu_metrics_debug': False, 'is_encoder_decoder': False, 'length_column_name': 'length', 'logging_first_step': False, 'repetition_penalty': 1, 'torch_compile_mode': None, 'add_cross_attention': False, 'evaluation_strategy': 'steps', 'forced_bos_token_id': None, 'forced_eos_token_id': None, 'fsdp_min_num_params': 0, 'neftune_noise_alpha': None, 'num_attention_heads': 32, 'num_key_value_heads': 32, 'quantization_config': {'load_in_4bit': True, 'load_in_8bit': False, 'quant_method': 'QuantizationMethod.BITS_AND_BYTES', 'llm_int8_threshold': 6, 'bnb_4bit_quant_type': 'nf4', 'llm_int8_skip_modules': None, 'bnb_4bit_compute_dtype': 'bfloat16', 'llm_int8_has_fp16_weight': False, 'bnb_4bit_use_double_quant': True, 'llm_int8_enable_fp32_cpu_offload': False}, 'skip_memory_metrics': True, 'tie_encoder_decoder': False, 'tie_word_embeddings': False, 'auto_find_batch_size': False, 'dataloader_drop_last': False, 'no_repeat_ngram_size': 0, 'num_return_sequences': 1, 'output_hidden_states': False, 'overwrite_output_dir': True, 'prediction_loss_only': False, 'push_to_hub_model_id': None, 'task_specific_params': None, 'transformers_version': '4.35.0', 'begin_suppress_tokens': None, 'dataloader_pin_memory': True, 'ddp_broadcast_buffers': None, 'metric_for_best_model': 'f1_bi', 'remove_invalid_values': False, 'remove_unused_columns': True, 'torch_compile_backend': None, 'dataloader_num_workers': 0, 'decoder_start_token_id': None, 'gradient_checkpointing': False, 'half_precision_backend': 'auto', 'label_smoothing_factor': 0, 'load_best_model_at_end': True, 'logging_nan_inf_filter': True, 'resume_from_checkpoint': None, 'chunk_size_feed_forward': 0, 'eval_accumulation_steps': None, 'max_position_embeddings': 4096, 'per_gpu_eval_batch_size': None, 'return_dict_in_generate': False, 'per_gpu_train_batch_size': None, 'push_to_hub_organization': None, 'include_tokens_per_second': False, 'ddp_find_unused_parameters': None, 'include_inputs_for_metrics': False, 'per_device_eval_batch_size': 8, 'use_legacy_prediction_loop': False, 'cross_attention_hidden_size': None, 'gradient_accumulation_steps': 1, 'per_device_train_batch_size': 8, 'encoder_no_repeat_ngram_size': 0, 'gradient_checkpointing_kwargs': None, 'exponential_decay_length_penalty': None, 'fsdp_transformer_layer_cls_to_wrap': None}",llama7|paged_adamw_8bit 8 1e-05 f1_bi 2|r21|0,"{'os': 'Linux-5.10.0-21-amd64-x86_64-with-glibc2.29', 'python': '3.8.10', 'heartbeatAt': '2023-11-15T20:38:35.695311', 'startedAt': '2023-11-15T20:38:34.820752', 'docker': None, 'cuda': None, 'args': ['-n', '2'], 'state': 'running', 'program': 'cp_train_template_llama.py', 'codePath': 'cp_train_template_llama.py', 'git': {'remote': 'https://github.com/marcinsawinski/clef23_eval.git', 'commit': '5ee747d1ef67d6aecf42314b8cd247d6f91ddd0c'}, 'email': 'marcin.sawinski@gmail.com', 'root': '/root/notebooks/msawinski/clef23_eval', 'host': 'c301b88b57d6', 'username': 'root', 'executable': '/usr/bin/python', 'cpu_count': 10, 'cpu_count_logical': 20, 'cpu_freq': {'current': 1219.3724999999997, 'min': 1200.0, 'max': 4420.0}, 'cpu_freq_per_core': [{'current': 1199.993, 'min': 1200.0, 'max': 4400.0}, {'current': 1200.718, 'min': 1200.0, 'max': 4400.0}, {'current': 1200.471, 'min': 1200.0, 'max': 4400.0}, {'current': 1200.388, 'min': 1200.0, 'max': 4400.0}, {'current': 1200.713, 'min': 1200.0, 'max': 4400.0}, {'current': 1200.171, 'min': 1200.0, 'max': 4400.0}, {'current': 1200.477, 'min': 1200.0, 'max': 4400.0}, {'current': 1200.478, 'min': 1200.0, 'max': 4400.0}, {'current': 1200.084, 'min': 1200.0, 'max': 4500.0}, {'current': 1199.999, 'min': 1200.0, 'max': 4500.0}, {'current': 1200.0, 'min': 1200.0, 'max': 4400.0}, {'current': 1200.11, 'min': 1200.0, 'max': 4400.0}, {'current': 1200.407, 'min': 1200.0, 'max': 4400.0}, {'current': 1200.18, 'min': 1200.0, 'max': 4400.0}, {'current': 1200.146, 'min': 1200.0, 'max': 4400.0}, {'current': 1200.012, 'min': 1200.0, 'max': 4400.0}, {'current': 1200.366, 'min': 1200.0, 'max': 4400.0}, {'current': 1200.148, 'min': 1200.0, 'max': 4400.0}, {'current': 1200.124, 'min': 1200.0, 'max': 4500.0}, {'current': 1199.856, 'min': 1200.0, 'max': 4500.0}], 'disk': {'total': 1738.1651229858398, 'used': 1515.7122688293457}, 'gpu': 'NVIDIA GeForce RTX 2080 Ti', 'gpu_count': 4, 'gpu_devices': [{'name': 'NVIDIA GeForce RTX 2080 Ti', 'memory_total': 11811160064}, {'name': 'NVIDIA GeForce RTX 2080 Ti', 'memory_total': 11811160064}, {'name': 'NVIDIA GeForce RTX 2080 Ti', 'memory_total': 11811160064}, {'name': 'NVIDIA GeForce RTX 2080 Ti', 'memory_total': 11811160064}], 'memory': {'total': 93.98457717895508}}","{'allocatedmax': 27.0, 'allocatedmed': 26.0, 'allocatedgbmax': 12.55, 'allocatedgbmed': 12.4}"
2,"{'eval/acc': 0.898, 'eval/prec': 0.8277945619335347, 'eval/steps_per_second': 0.113, 'eval/samples_per_second': 0.908, '_runtime': 90920.31346940994, 'eval/f1_bi': 0.8430769230769232, 'eval/f1_ma': 0.8837606837606838, 'train/loss': 0.3721, 'eval/runtime': 1101.8271, 'train/global_step': 640, 'eval/rec': 0.8589341692789969, 'train/epoch': 0.67, 'train/learning_rate': 6.694386694386695e-06, '_step': 127, 'eval/loss': 0.32614392042160034, '_timestamp': 1700129187.5962725}","{'bf16': False, 'fp16': True, 'fsdp': [], 'seed': 42, 'tf32': None, 'debug': [], 'optim': 'paged_adamw_8bit', 'top_k': 50, 'top_p': 1, 'prefix': None, 'do_eval': True, 'no_cuda': False, 'use_cpu': False, 'do_train': False, 'id2label': {'0': 'LABEL_0', '1': 'LABEL_1'}, 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'run_name': './output-trainer', 'use_ipex': False, 'adafactor': False, 'data_seed': None, 'deepspeed': None, 'do_sample': False, 'hub_token': '<HUB_TOKEN>', 'log_level': 'passive', 'max_steps': -1, 'num_beams': 1, 'ray_scope': 'last', 'report_to': ['wandb'], 'typical_p': 1, 'use_cache': True, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'do_predict': False, 'eval_delay': 0, 'eval_steps': 10, 'hidden_act': 'silu', 'is_decoder': False, 'local_rank': 0, 'max_length': 20, 'min_length': 0, 'model_type': 'llama', 'optim_args': None, 'output_dir': './output-trainer', 'past_index': -1, 'rope_theta': 10000, 'save_steps': 100, 'vocab_size': 32000, 'ddp_backend': None, 'ddp_timeout': 1800, 'fsdp_config': {'xla': False, 'min_num_params': 0, 'xla_fsdp_grad_ckpt': False}, 'hidden_size': 8192, 'label_names': None, 'logging_dir': './output-trainer/logs', 'push_to_hub': False, 'return_dict': True, 'temperature': 1, 'torch_dtype': 'float16', 'torchdynamo': None, 'torchscript': False, 'adam_epsilon': 1e-08, 'bos_token_id': 1, 'disable_tqdm': False, 'eos_token_id': 2, 'fp16_backend': 'auto', 'hub_model_id': None, 'hub_strategy': 'every_save', 'pad_token_id': 2, 'problem_type': None, 'pruned_heads': {}, 'rms_norm_eps': 1e-05, 'rope_scaling': None, 'sep_token_id': None, 'use_bfloat16': False, 'warmup_ratio': 0, 'warmup_steps': 0, 'weight_decay': 0.01, 'architectures': ['LlamaForCausalLM'], 'bad_words_ids': None, 'jit_mode_eval': False, 'learning_rate': 1e-05, 'logging_steps': 10, 'max_grad_norm': 1, 'mp_parameters': '', 'output_scores': False, 'save_strategy': 'steps', 'split_batches': False, 'torch_compile': False, 'tpu_num_cores': None, 'attention_bias': False, 'bf16_full_eval': False, 'early_stopping': False, 'fp16_full_eval': False, 'fp16_opt_level': 'O1', 'length_penalty': 1, 'pretraining_tp': 1, 'tf_legacy_loss': False, 'use_mps_device': False, 'finetuning_task': None, 'group_by_length': False, 'hub_always_push': False, 'num_beam_groups': 1, 'suppress_tokens': None, 'tokenizer_class': None, 'deepspeed_plugin': None, 'dispatch_batches': None, 'full_determinism': False, 'hub_private_repo': False, 'ignore_data_skip': False, 'log_on_each_node': True, 'logging_strategy': 'steps', 'num_train_epochs': 2, 'save_safetensors': True, 'save_total_limit': 12, 'ddp_bucket_cap_mb': None, 'distributed_state': 'Distributed environment: NO\nNum processes: 1\nProcess index: 0\nLocal process index: 0\nDevice: cuda\n', 'diversity_penalty': 0, 'greater_is_better': True, 'initializer_range': 0.02, 'intermediate_size': 28672, 'log_level_replica': 'warning', 'lr_scheduler_type': 'linear', 'num_hidden_layers': 80, 'output_attentions': False, 'push_to_hub_token': '<PUSH_TO_HUB_TOKEN>', 'save_on_each_node': False, 'tpu_metrics_debug': False, 'is_encoder_decoder': False, 'length_column_name': 'length', 'logging_first_step': False, 'repetition_penalty': 1, 'torch_compile_mode': None, 'add_cross_attention': False, 'evaluation_strategy': 'steps', 'forced_bos_token_id': None, 'forced_eos_token_id': None, 'fsdp_min_num_params': 0, 'neftune_noise_alpha': None, 'num_attention_heads': 64, 'num_key_value_heads': 8, 'quantization_config': {'load_in_4bit': True, 'load_in_8bit': False, 'quant_method': 'QuantizationMethod.BITS_AND_BYTES', 'llm_int8_threshold': 6, 'bnb_4bit_quant_type': 'nf4', 'llm_int8_skip_modules': None, 'bnb_4bit_compute_dtype': 'bfloat16', 'llm_int8_has_fp16_weight': False, 'bnb_4bit_use_double_quant': True, 'llm_int8_enable_fp32_cpu_offload': False}, 'skip_memory_metrics': True, 'tie_encoder_decoder': False, 'tie_word_embeddings': False, 'auto_find_batch_size': False, 'dataloader_drop_last': False, 'no_repeat_ngram_size': 0, 'num_return_sequences': 1, 'output_hidden_states': False, 'overwrite_output_dir': True, 'prediction_loss_only': False, 'push_to_hub_model_id': None, 'task_specific_params': None, 'transformers_version': '4.35.0', 'begin_suppress_tokens': None, 'dataloader_pin_memory': True, 'ddp_broadcast_buffers': None, 'metric_for_best_model': 'f1_bi', 'remove_invalid_values': False, 'remove_unused_columns': True, 'torch_compile_backend': None, 'dataloader_num_workers': 0, 'decoder_start_token_id': None, 'gradient_checkpointing': False, 'half_precision_backend': 'auto', 'label_smoothing_factor': 0, 'load_best_model_at_end': True, 'logging_nan_inf_filter': True, 'resume_from_checkpoint': None, 'chunk_size_feed_forward': 0, 'eval_accumulation_steps': None, 'max_position_embeddings': 4096, 'per_gpu_eval_batch_size': None, 'return_dict_in_generate': False, 'per_gpu_train_batch_size': None, 'push_to_hub_organization': None, 'include_tokens_per_second': False, 'ddp_find_unused_parameters': None, 'include_inputs_for_metrics': False, 'per_device_eval_batch_size': 8, 'use_legacy_prediction_loop': False, 'cross_attention_hidden_size': None, 'gradient_accumulation_steps': 1, 'per_device_train_batch_size': 8, 'encoder_no_repeat_ngram_size': 0, 'gradient_checkpointing_kwargs': None, 'exponential_decay_length_penalty': None, 'fsdp_transformer_layer_cls_to_wrap': None}",llama70|paged_adamw_8bit 8 1e-05 f1_bi 2|r21|0,"{'os': 'Linux-5.10.0-26-cloud-amd64-x86_64-with-glibc2.31', 'python': '3.10.13', 'heartbeatAt': '2023-11-15T08:51:11.774945', 'startedAt': '2023-11-15T08:51:07.276917', 'docker': None, 'cuda': None, 'args': [], 'state': 'running', 'program': '/home/jupyter/clef23_eval/cp_train_template_llama.py', 'codePathLocal': 'cp_train_template_llama.py', 'codePath': 'cp_train_template_llama.py', 'git': {'remote': 'https://github.com/marcinsawinski/clef23_eval.git', 'commit': '5ee747d1ef67d6aecf42314b8cd247d6f91ddd0c'}, 'email': 'marcin.sawinski@gmail.com', 'root': '/home/jupyter/clef23_eval', 'host': 'clef-l4-8', 'username': 'jupyter', 'executable': '/opt/conda/bin/python', 'cpu_count': 48, 'cpu_count_logical': 96, 'cpu_freq': {'current': 2200.1939999999972, 'min': 0.0, 'max': 0.0}, 'cpu_freq_per_core': [{'current': 2200.194, 'min': 0.0, 'max': 0.0}, {'current': 2200.194, 'min': 0.0, 'max': 0.0}, {'current': 2200.194, 'min': 0.0, 'max': 0.0}, {'current': 2200.194, 'min': 0.0, 'max': 0.0}, {'current': 2200.194, 'min': 0.0, 'max': 0.0}, {'current': 2200.194, 'min': 0.0, 'max': 0.0}, {'current': 2200.194, 'min': 0.0, 'max': 0.0}, {'current': 2200.194, 'min': 0.0, 'max': 0.0}, {'current': 2200.194, 'min': 0.0, 'max': 0.0}, {'current': 2200.194, 'min': 0.0, 'max': 0.0}, {'current': 2200.194, 'min': 0.0, 'max': 0.0}, {'current': 2200.194, 'min': 0.0, 'max': 0.0}, {'current': 2200.194, 'min': 0.0, 'max': 0.0}, {'current': 2200.194, 'min': 0.0, 'max': 0.0}, {'current': 2200.194, 'min': 0.0, 'max': 0.0}, {'current': 2200.194, 'min': 0.0, 'max': 0.0}, {'current': 2200.194, 'min': 0.0, 'max': 0.0}, {'current': 2200.194, 'min': 0.0, 'max': 0.0}, {'current': 2200.194, 'min': 0.0, 'max': 0.0}, {'current': 2200.194, 'min': 0.0, 'max': 0.0}, {'current': 2200.194, 'min': 0.0, 'max': 0.0}, {'current': 2200.194, 'min': 0.0, 'max': 0.0}, {'current': 2200.194, 'min': 0.0, 'max': 0.0}, {'current': 2200.194, 'min': 0.0, 'max': 0.0}, {'current': 2200.194, 'min': 0.0, 'max': 0.0}, {'current': 2200.194, 'min': 0.0, 'max': 0.0}, {'current': 2200.194, 'min': 0.0, 'max': 0.0}, {'current': 2200.194, 'min': 0.0, 'max': 0.0}, {'current': 2200.194, 'min': 0.0, 'max': 0.0}, {'current': 2200.194, 'min': 0.0, 'max': 0.0}, {'current': 2200.194, 'min': 0.0, 'max': 0.0}, {'current': 2200.194, 'min': 0.0, 'max': 0.0}, {'current': 2200.194, 'min': 0.0, 'max': 0.0}, {'current': 2200.194, 'min': 0.0, 'max': 0.0}, {'current': 2200.194, 'min': 0.0, 'max': 0.0}, {'current': 2200.194, 'min': 0.0, 'max': 0.0}, {'current': 2200.194, 'min': 0.0, 'max': 0.0}, {'current': 2200.194, 'min': 0.0, 'max': 0.0}, {'current': 2200.194, 'min': 0.0, 'max': 0.0}, {'current': 2200.194, 'min': 0.0, 'max': 0.0}, {'current': 2200.194, 'min': 0.0, 'max': 0.0}, {'current': 2200.194, 'min': 0.0, 'max': 0.0}, {'current': 2200.194, 'min': 0.0, 'max': 0.0}, {'current': 2200.194, 'min': 0.0, 'max': 0.0}, {'current': 2200.194, 'min': 0.0, 'max': 0.0}, {'current': 2200.194, 'min': 0.0, 'max': 0.0}, {'current': 2200.194, 'min': 0.0, 'max': 0.0}, {'current': 2200.194, 'min': 0.0, 'max': 0.0}, {'current': 2200.194, 'min': 0.0, 'max': 0.0}, {'current': 2200.194, 'min': 0.0, 'max': 0.0}, {'current': 2200.194, 'min': 0.0, 'max': 0.0}, {'current': 2200.194, 'min': 0.0, 'max': 0.0}, {'current': 2200.194, 'min': 0.0, 'max': 0.0}, {'current': 2200.194, 'min': 0.0, 'max': 0.0}, {'current': 2200.194, 'min': 0.0, 'max': 0.0}, {'current': 2200.194, 'min': 0.0, 'max': 0.0}, {'current': 2200.194, 'min': 0.0, 'max': 0.0}, {'current': 2200.194, 'min': 0.0, 'max': 0.0}, {'current': 2200.194, 'min': 0.0, 'max': 0.0}, {'current': 2200.194, 'min': 0.0, 'max': 0.0}, {'current': 2200.194, 'min': 0.0, 'max': 0.0}, {'current': 2200.194, 'min': 0.0, 'max': 0.0}, {'current': 2200.194, 'min': 0.0, 'max': 0.0}, {'current': 2200.194, 'min': 0.0, 'max': 0.0}, {'current': 2200.194, 'min': 0.0, 'max': 0.0}, {'current': 2200.194, 'min': 0.0, 'max': 0.0}, {'current': 2200.194, 'min': 0.0, 'max': 0.0}, {'current': 2200.194, 'min': 0.0, 'max': 0.0}, {'current': 2200.194, 'min': 0.0, 'max': 0.0}, {'current': 2200.194, 'min': 0.0, 'max': 0.0}, {'current': 2200.194, 'min': 0.0, 'max': 0.0}, {'current': 2200.194, 'min': 0.0, 'max': 0.0}, {'current': 2200.194, 'min': 0.0, 'max': 0.0}, {'current': 2200.194, 'min': 0.0, 'max': 0.0}, {'current': 2200.194, 'min': 0.0, 'max': 0.0}, {'current': 2200.194, 'min': 0.0, 'max': 0.0}, {'current': 2200.194, 'min': 0.0, 'max': 0.0}, {'current': 2200.194, 'min': 0.0, 'max': 0.0}, {'current': 2200.194, 'min': 0.0, 'max': 0.0}, {'current': 2200.194, 'min': 0.0, 'max': 0.0}, {'current': 2200.194, 'min': 0.0, 'max': 0.0}, {'current': 2200.194, 'min': 0.0, 'max': 0.0}, {'current': 2200.194, 'min': 0.0, 'max': 0.0}, {'current': 2200.194, 'min': 0.0, 'max': 0.0}, {'current': 2200.194, 'min': 0.0, 'max': 0.0}, {'current': 2200.194, 'min': 0.0, 'max': 0.0}, {'current': 2200.194, 'min': 0.0, 'max': 0.0}, {'current': 2200.194, 'min': 0.0, 'max': 0.0}, {'current': 2200.194, 'min': 0.0, 'max': 0.0}, {'current': 2200.194, 'min': 0.0, 'max': 0.0}, {'current': 2200.194, 'min': 0.0, 'max': 0.0}, {'current': 2200.194, 'min': 0.0, 'max': 0.0}, {'current': 2200.194, 'min': 0.0, 'max': 0.0}, {'current': 2200.194, 'min': 0.0, 'max': 0.0}, {'current': 2200.194, 'min': 0.0, 'max': 0.0}, {'current': 2200.194, 'min': 0.0, 'max': 0.0}], 'disk': {'/': {'total': 147.40181350708008, 'used': 62.449363708496094}}, 'gpu': 'NVIDIA L4', 'gpu_count': 8, 'gpu_devices': [{'name': 'NVIDIA L4', 'memory_total': 24152899584}, {'name': 'NVIDIA L4', 'memory_total': 24152899584}, {'name': 'NVIDIA L4', 'memory_total': 24152899584}, {'name': 'NVIDIA L4', 'memory_total': 24152899584}, {'name': 'NVIDIA L4', 'memory_total': 24152899584}, {'name': 'NVIDIA L4', 'memory_total': 24152899584}, {'name': 'NVIDIA L4', 'memory_total': 24152899584}, {'name': 'NVIDIA L4', 'memory_total': 24152899584}], 'memory': {'total': 377.8818016052246}}","{'allocatedmax': 44.0, 'allocatedmed': 44.0, 'allocatedgbmax': 85.0, 'allocatedgbmed': 85.0}"
3,"{'_step': 370, 'test_recall': 0.713, 'train/epoch': 1.88, 'dev_test_precision': 0.941, 'eval/prec': 0.8910891089108911, 'eval/f1_bi': 0.8681672025723473, 'dev_test_recall': 0.623, 'train/total_flos': 1.103654583263232e+17, 'dev_test_f1': 0.75, 'eval/runtime': 116.5827, 'dev_test_accuracy': 0.792, '_timestamp': 1700064951.1938324, '_wandb': {'runtime': 28218}, '_runtime': 28221.11438632011, 'test_precision': 0.928, 'train/global_step': 1810, 'train/train_samples_per_second': 0.551, 'train/train_steps_per_second': 0.069, 'test_f1': 0.806, 'eval/loss': 0.3352576196193695, 'train/loss': 0.0843, 'test_accuracy': 0.884, 'train/train_loss': 0.34167032457517654, 'train/train_runtime': 27931.2268, 'eval/rec': 0.8463949843260188, 'eval/f1_ma': 0.9043303356838516, 'eval/samples_per_second': 8.578, 'eval/acc': 0.918, 'train/learning_rate': 6.237006237006238e-07, 'eval/steps_per_second': 1.072}","{'bf16': False, 'fp16': True, 'fsdp': [], 'seed': 42, 'tf32': None, 'debug': [], 'optim': 'paged_adamw_8bit', 'top_k': 50, 'top_p': 1, 'prefix': None, 'do_eval': True, 'no_cuda': False, 'use_cpu': False, 'do_train': False, 'id2label': {'0': 'LABEL_0', '1': 'LABEL_1'}, 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'run_name': './output-trainer', 'use_ipex': False, 'adafactor': False, 'data_seed': None, 'deepspeed': None, 'do_sample': False, 'hub_token': '<HUB_TOKEN>', 'log_level': 'passive', 'max_steps': -1, 'num_beams': 1, 'ray_scope': 'last', 'report_to': ['wandb'], 'typical_p': 1, 'use_cache': True, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'do_predict': False, 'eval_delay': 0, 'eval_steps': 10, 'hidden_act': 'silu', 'is_decoder': False, 'local_rank': 0, 'max_length': 20, 'min_length': 0, 'model_type': 'llama', 'optim_args': None, 'output_dir': './output-trainer', 'past_index': -1, 'rope_theta': 10000, 'save_steps': 100, 'vocab_size': 32000, 'ddp_backend': None, 'ddp_timeout': 1800, 'fsdp_config': {'xla': False, 'min_num_params': 0, 'xla_fsdp_grad_ckpt': False}, 'hidden_size': 4096, 'label_names': None, 'logging_dir': './output-trainer/logs', 'push_to_hub': False, 'return_dict': True, 'temperature': 1, 'torch_dtype': 'float16', 'torchdynamo': None, 'torchscript': False, 'adam_epsilon': 1e-08, 'bos_token_id': 1, 'disable_tqdm': False, 'eos_token_id': 2, 'fp16_backend': 'auto', 'hub_model_id': None, 'hub_strategy': 'every_save', 'pad_token_id': 2, 'problem_type': None, 'pruned_heads': {}, 'rms_norm_eps': 1e-05, 'rope_scaling': None, 'sep_token_id': None, 'use_bfloat16': False, 'warmup_ratio': 0, 'warmup_steps': 0, 'weight_decay': 0.01, 'architectures': ['LlamaForCausalLM'], 'bad_words_ids': None, 'jit_mode_eval': False, 'learning_rate': 1e-05, 'logging_steps': 10, 'max_grad_norm': 1, 'mp_parameters': '', 'output_scores': False, 'save_strategy': 'steps', 'split_batches': False, 'torch_compile': False, 'tpu_num_cores': None, 'attention_bias': False, 'bf16_full_eval': False, 'early_stopping': False, 'fp16_full_eval': False, 'fp16_opt_level': 'O1', 'length_penalty': 1, 'pretraining_tp': 1, 'tf_legacy_loss': False, 'use_mps_device': False, 'finetuning_task': None, 'group_by_length': False, 'hub_always_push': False, 'num_beam_groups': 1, 'suppress_tokens': None, 'tokenizer_class': None, 'deepspeed_plugin': None, 'dispatch_batches': None, 'full_determinism': False, 'hub_private_repo': False, 'ignore_data_skip': False, 'log_on_each_node': True, 'logging_strategy': 'steps', 'num_train_epochs': 2, 'save_safetensors': True, 'save_total_limit': 12, 'ddp_bucket_cap_mb': None, 'distributed_state': 'Distributed environment: NO\nNum processes: 1\nProcess index: 0\nLocal process index: 0\nDevice: cuda\n', 'diversity_penalty': 0, 'greater_is_better': True, 'initializer_range': 0.02, 'intermediate_size': 11008, 'log_level_replica': 'warning', 'lr_scheduler_type': 'linear', 'num_hidden_layers': 32, 'output_attentions': False, 'push_to_hub_token': '<PUSH_TO_HUB_TOKEN>', 'save_on_each_node': False, 'tpu_metrics_debug': False, 'is_encoder_decoder': False, 'length_column_name': 'length', 'logging_first_step': False, 'repetition_penalty': 1, 'torch_compile_mode': None, 'add_cross_attention': False, 'evaluation_strategy': 'steps', 'forced_bos_token_id': None, 'forced_eos_token_id': None, 'fsdp_min_num_params': 0, 'neftune_noise_alpha': None, 'num_attention_heads': 32, 'num_key_value_heads': 32, 'quantization_config': {'load_in_4bit': True, 'load_in_8bit': False, 'quant_method': 'QuantizationMethod.BITS_AND_BYTES', 'llm_int8_threshold': 6, 'bnb_4bit_quant_type': 'nf4', 'llm_int8_skip_modules': None, 'bnb_4bit_compute_dtype': 'bfloat16', 'llm_int8_has_fp16_weight': False, 'bnb_4bit_use_double_quant': True, 'llm_int8_enable_fp32_cpu_offload': False}, 'skip_memory_metrics': True, 'tie_encoder_decoder': False, 'tie_word_embeddings': False, 'auto_find_batch_size': False, 'dataloader_drop_last': False, 'no_repeat_ngram_size': 0, 'num_return_sequences': 1, 'output_hidden_states': False, 'overwrite_output_dir': True, 'prediction_loss_only': False, 'push_to_hub_model_id': None, 'task_specific_params': None, 'transformers_version': '4.35.0', 'begin_suppress_tokens': None, 'dataloader_pin_memory': True, 'ddp_broadcast_buffers': None, 'metric_for_best_model': 'f1_bi', 'remove_invalid_values': False, 'remove_unused_columns': True, 'torch_compile_backend': None, 'dataloader_num_workers': 0, 'decoder_start_token_id': None, 'gradient_checkpointing': False, 'half_precision_backend': 'auto', 'label_smoothing_factor': 0, 'load_best_model_at_end': True, 'logging_nan_inf_filter': True, 'resume_from_checkpoint': None, 'chunk_size_feed_forward': 0, 'eval_accumulation_steps': None, 'max_position_embeddings': 4096, 'per_gpu_eval_batch_size': None, 'return_dict_in_generate': False, 'per_gpu_train_batch_size': None, 'push_to_hub_organization': None, 'include_tokens_per_second': False, 'ddp_find_unused_parameters': None, 'include_inputs_for_metrics': False, 'per_device_eval_batch_size': 8, 'use_legacy_prediction_loop': False, 'cross_attention_hidden_size': None, 'gradient_accumulation_steps': 1, 'per_device_train_batch_size': 8, 'encoder_no_repeat_ngram_size': 0, 'gradient_checkpointing_kwargs': None, 'exponential_decay_length_penalty': None, 'fsdp_transformer_layer_cls_to_wrap': None}",llama7|paged_adamw_8bit 8 1e-05 f1_bi 2|r21|0,"{'os': 'Linux-5.10.0-26-cloud-amd64-x86_64-with-glibc2.31', 'python': '3.10.13', 'heartbeatAt': '2023-11-15T08:25:33.230707', 'startedAt': '2023-11-15T08:25:30.073494', 'docker': None, 'cuda': None, 'args': [], 'state': 'running', 'program': '/home/jupyter/clef23_eval/cp_train_template_llama.py', 'codePathLocal': 'cp_train_template_llama.py', 'codePath': 'cp_train_template_llama.py', 'git': {'remote': 'https://github.com/marcinsawinski/clef23_eval.git', 'commit': '5ee747d1ef67d6aecf42314b8cd247d6f91ddd0c'}, 'email': None, 'root': '/home/jupyter/clef23_eval', 'host': 'clef-l4-4', 'username': 'jupyter', 'executable': '/opt/conda/bin/python', 'cpu_count': 24, 'cpu_count_logical': 48, 'cpu_freq': {'current': 2200.2060000000015, 'min': 0.0, 'max': 0.0}, 'cpu_freq_per_core': [{'current': 2200.206, 'min': 0.0, 'max': 0.0}, {'current': 2200.206, 'min': 0.0, 'max': 0.0}, {'current': 2200.206, 'min': 0.0, 'max': 0.0}, {'current': 2200.206, 'min': 0.0, 'max': 0.0}, {'current': 2200.206, 'min': 0.0, 'max': 0.0}, {'current': 2200.206, 'min': 0.0, 'max': 0.0}, {'current': 2200.206, 'min': 0.0, 'max': 0.0}, {'current': 2200.206, 'min': 0.0, 'max': 0.0}, {'current': 2200.206, 'min': 0.0, 'max': 0.0}, {'current': 2200.206, 'min': 0.0, 'max': 0.0}, {'current': 2200.206, 'min': 0.0, 'max': 0.0}, {'current': 2200.206, 'min': 0.0, 'max': 0.0}, {'current': 2200.206, 'min': 0.0, 'max': 0.0}, {'current': 2200.206, 'min': 0.0, 'max': 0.0}, {'current': 2200.206, 'min': 0.0, 'max': 0.0}, {'current': 2200.206, 'min': 0.0, 'max': 0.0}, {'current': 2200.206, 'min': 0.0, 'max': 0.0}, {'current': 2200.206, 'min': 0.0, 'max': 0.0}, {'current': 2200.206, 'min': 0.0, 'max': 0.0}, {'current': 2200.206, 'min': 0.0, 'max': 0.0}, {'current': 2200.206, 'min': 0.0, 'max': 0.0}, {'current': 2200.206, 'min': 0.0, 'max': 0.0}, {'current': 2200.206, 'min': 0.0, 'max': 0.0}, {'current': 2200.206, 'min': 0.0, 'max': 0.0}, {'current': 2200.206, 'min': 0.0, 'max': 0.0}, {'current': 2200.206, 'min': 0.0, 'max': 0.0}, {'current': 2200.206, 'min': 0.0, 'max': 0.0}, {'current': 2200.206, 'min': 0.0, 'max': 0.0}, {'current': 2200.206, 'min': 0.0, 'max': 0.0}, {'current': 2200.206, 'min': 0.0, 'max': 0.0}, {'current': 2200.206, 'min': 0.0, 'max': 0.0}, {'current': 2200.206, 'min': 0.0, 'max': 0.0}, {'current': 2200.206, 'min': 0.0, 'max': 0.0}, {'current': 2200.206, 'min': 0.0, 'max': 0.0}, {'current': 2200.206, 'min': 0.0, 'max': 0.0}, {'current': 2200.206, 'min': 0.0, 'max': 0.0}, {'current': 2200.206, 'min': 0.0, 'max': 0.0}, {'current': 2200.206, 'min': 0.0, 'max': 0.0}, {'current': 2200.206, 'min': 0.0, 'max': 0.0}, {'current': 2200.206, 'min': 0.0, 'max': 0.0}, {'current': 2200.206, 'min': 0.0, 'max': 0.0}, {'current': 2200.206, 'min': 0.0, 'max': 0.0}, {'current': 2200.206, 'min': 0.0, 'max': 0.0}, {'current': 2200.206, 'min': 0.0, 'max': 0.0}, {'current': 2200.206, 'min': 0.0, 'max': 0.0}, {'current': 2200.206, 'min': 0.0, 'max': 0.0}, {'current': 2200.206, 'min': 0.0, 'max': 0.0}, {'current': 2200.206, 'min': 0.0, 'max': 0.0}], 'disk': {'/': {'total': 147.40181350708008, 'used': 75.15691757202148}}, 'gpu': 'NVIDIA L4', 'gpu_count': 4, 'gpu_devices': [{'name': 'NVIDIA L4', 'memory_total': 24152899584}, {'name': 'NVIDIA L4', 'memory_total': 24152899584}, {'name': 'NVIDIA L4', 'memory_total': 24152899584}, {'name': 'NVIDIA L4', 'memory_total': 24152899584}], 'memory': {'total': 188.70611572265625}}","{'allocatedmax': 18.0, 'allocatedmed': 17.0, 'allocatedgbmax': 16.92, 'allocatedgbmed': 16.79}"
4,"{'eval/steps_per_second': 0.8, 'test_precision': 0.92, 'train/train_loss': 0.2894843046116618, 'train/train_steps_per_second': 0.083, '_wandb': {'runtime': 23664}, 'eval/prec': 0.9190140845070424, 'dev_test_f1': 0.759, 'eval/runtime': 156.1842, 'test_accuracy': 0.89, 'dev_test_accuracy': 0.796, 'eval/acc': 0.919, 'eval/rec': 0.8181818181818182, '_timestamp': 1700056742.7562912, 'train/train_samples_per_second': 0.66, 'test_recall': 0.741, 'train/total_flos': 1.348028997359616e+17, 'dev_test_precision': 0.932, 'eval/samples_per_second': 6.403, 'test_f1': 0.821, 'train/loss': 0.0474, 'dev_test_recall': 0.64, 'train/learning_rate': 4.142411642411643e-06, '_runtime': 23665.78507709503, 'eval/f1_bi': 0.8656716417910449, 'train/global_step': 1130, 'train/train_runtime': 23304.7849, '_step': 234, 'eval/loss': 0.30852824449539185, 'eval/f1_ma': 0.9038451265504974, 'train/epoch': 1.17}","{'bf16': False, 'fp16': True, 'fsdp': [], 'seed': 42, 'tf32': None, 'debug': [], 'optim': 'paged_adamw_8bit', 'top_k': 50, 'top_p': 1, 'prefix': None, 'do_eval': True, 'no_cuda': False, 'use_cpu': False, 'do_train': False, 'id2label': {'0': 'LABEL_0', '1': 'LABEL_1'}, 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'run_name': './output-trainer', 'use_ipex': False, 'adafactor': False, 'data_seed': None, 'deepspeed': None, 'do_sample': False, 'hub_token': '<HUB_TOKEN>', 'log_level': 'passive', 'max_steps': -1, 'num_beams': 1, 'ray_scope': 'last', 'report_to': ['wandb'], 'typical_p': 1, 'use_cache': True, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'do_predict': False, 'eval_delay': 0, 'eval_steps': 10, 'hidden_act': 'silu', 'is_decoder': False, 'local_rank': 0, 'max_length': 20, 'min_length': 0, 'model_type': 'llama', 'optim_args': None, 'output_dir': './output-trainer', 'past_index': -1, 'rope_theta': 10000, 'save_steps': 100, 'vocab_size': 32000, 'ddp_backend': None, 'ddp_timeout': 1800, 'fsdp_config': {'xla': False, 'min_num_params': 0, 'xla_fsdp_grad_ckpt': False}, 'hidden_size': 5120, 'label_names': None, 'logging_dir': './output-trainer/logs', 'push_to_hub': False, 'return_dict': True, 'temperature': 1, 'torch_dtype': 'float16', 'torchdynamo': None, 'torchscript': False, 'adam_epsilon': 1e-08, 'bos_token_id': 1, 'disable_tqdm': False, 'eos_token_id': 2, 'fp16_backend': 'auto', 'hub_model_id': None, 'hub_strategy': 'every_save', 'pad_token_id': 2, 'problem_type': None, 'pruned_heads': {}, 'rms_norm_eps': 1e-05, 'rope_scaling': None, 'sep_token_id': None, 'use_bfloat16': False, 'warmup_ratio': 0, 'warmup_steps': 0, 'weight_decay': 0.01, 'architectures': ['LlamaForCausalLM'], 'bad_words_ids': None, 'jit_mode_eval': False, 'learning_rate': 1e-05, 'logging_steps': 10, 'max_grad_norm': 1, 'mp_parameters': '', 'output_scores': False, 'save_strategy': 'steps', 'split_batches': False, 'torch_compile': False, 'tpu_num_cores': None, 'attention_bias': False, 'bf16_full_eval': False, 'early_stopping': False, 'fp16_full_eval': False, 'fp16_opt_level': 'O1', 'length_penalty': 1, 'pretraining_tp': 1, 'tf_legacy_loss': False, 'use_mps_device': False, 'finetuning_task': None, 'group_by_length': False, 'hub_always_push': False, 'num_beam_groups': 1, 'suppress_tokens': None, 'tokenizer_class': None, 'deepspeed_plugin': None, 'dispatch_batches': None, 'full_determinism': False, 'hub_private_repo': False, 'ignore_data_skip': False, 'log_on_each_node': True, 'logging_strategy': 'steps', 'num_train_epochs': 2, 'save_safetensors': True, 'save_total_limit': 12, 'ddp_bucket_cap_mb': None, 'distributed_state': 'Distributed environment: NO\nNum processes: 1\nProcess index: 0\nLocal process index: 0\nDevice: cuda\n', 'diversity_penalty': 0, 'greater_is_better': True, 'initializer_range': 0.02, 'intermediate_size': 13824, 'log_level_replica': 'warning', 'lr_scheduler_type': 'linear', 'num_hidden_layers': 40, 'output_attentions': False, 'push_to_hub_token': '<PUSH_TO_HUB_TOKEN>', 'save_on_each_node': False, 'tpu_metrics_debug': False, 'is_encoder_decoder': False, 'length_column_name': 'length', 'logging_first_step': False, 'repetition_penalty': 1, 'torch_compile_mode': None, 'add_cross_attention': False, 'evaluation_strategy': 'steps', 'forced_bos_token_id': None, 'forced_eos_token_id': None, 'fsdp_min_num_params': 0, 'neftune_noise_alpha': None, 'num_attention_heads': 40, 'num_key_value_heads': 40, 'quantization_config': {'load_in_4bit': True, 'load_in_8bit': False, 'quant_method': 'QuantizationMethod.BITS_AND_BYTES', 'llm_int8_threshold': 6, 'bnb_4bit_quant_type': 'nf4', 'llm_int8_skip_modules': None, 'bnb_4bit_compute_dtype': 'bfloat16', 'llm_int8_has_fp16_weight': False, 'bnb_4bit_use_double_quant': True, 'llm_int8_enable_fp32_cpu_offload': False}, 'skip_memory_metrics': True, 'tie_encoder_decoder': False, 'tie_word_embeddings': False, 'auto_find_batch_size': False, 'dataloader_drop_last': False, 'no_repeat_ngram_size': 0, 'num_return_sequences': 1, 'output_hidden_states': False, 'overwrite_output_dir': True, 'prediction_loss_only': False, 'push_to_hub_model_id': None, 'task_specific_params': None, 'transformers_version': '4.35.0', 'begin_suppress_tokens': None, 'dataloader_pin_memory': True, 'ddp_broadcast_buffers': None, 'metric_for_best_model': 'f1_bi', 'remove_invalid_values': False, 'remove_unused_columns': True, 'torch_compile_backend': None, 'dataloader_num_workers': 0, 'decoder_start_token_id': None, 'gradient_checkpointing': False, 'half_precision_backend': 'auto', 'label_smoothing_factor': 0, 'load_best_model_at_end': True, 'logging_nan_inf_filter': True, 'resume_from_checkpoint': None, 'chunk_size_feed_forward': 0, 'eval_accumulation_steps': None, 'max_position_embeddings': 4096, 'per_gpu_eval_batch_size': None, 'return_dict_in_generate': False, 'per_gpu_train_batch_size': None, 'push_to_hub_organization': None, 'include_tokens_per_second': False, 'ddp_find_unused_parameters': None, 'include_inputs_for_metrics': False, 'per_device_eval_batch_size': 8, 'use_legacy_prediction_loop': False, 'cross_attention_hidden_size': None, 'gradient_accumulation_steps': 1, 'per_device_train_batch_size': 8, 'encoder_no_repeat_ngram_size': 0, 'gradient_checkpointing_kwargs': None, 'exponential_decay_length_penalty': None, 'fsdp_transformer_layer_cls_to_wrap': None}",llama13|paged_adamw_8bit 8 1e-05 f1_bi 2|r21|0,"{'os': 'Linux-5.10.0-21-amd64-x86_64-with-glibc2.29', 'python': '3.8.10', 'heartbeatAt': '2023-11-15T07:24:38.320420', 'startedAt': '2023-11-15T07:24:36.959310', 'docker': None, 'cuda': None, 'args': [], 'state': 'running', 'program': 'cp_train_template_llama.py', 'codePath': 'cp_train_template_llama.py', 'git': {'remote': 'https://github.com/marcinsawinski/clef23_eval.git', 'commit': '8d3c849466a4c1e2323f474eb795423f2e69551a'}, 'email': 'marcin.sawinski@gmail.com', 'root': '/root/notebooks/msawinski/clef23_eval', 'host': 'c301b88b57d6', 'username': 'root', 'executable': '/usr/bin/python', 'cpu_count': 10, 'cpu_count_logical': 20, 'cpu_freq': {'current': 1202.6614500000003, 'min': 1200.0, 'max': 4420.0}, 'cpu_freq_per_core': [{'current': 1200.186, 'min': 1200.0, 'max': 4400.0}, {'current': 1200.302, 'min': 1200.0, 'max': 4400.0}, {'current': 1200.581, 'min': 1200.0, 'max': 4400.0}, {'current': 1200.904, 'min': 1200.0, 'max': 4400.0}, {'current': 1288.285, 'min': 1200.0, 'max': 4400.0}, {'current': 1200.765, 'min': 1200.0, 'max': 4400.0}, {'current': 1200.633, 'min': 1200.0, 'max': 4400.0}, {'current': 1279.089, 'min': 1200.0, 'max': 4400.0}, {'current': 1200.359, 'min': 1200.0, 'max': 4500.0}, {'current': 1200.348, 'min': 1200.0, 'max': 4500.0}, {'current': 1200.763, 'min': 1200.0, 'max': 4400.0}, {'current': 1200.435, 'min': 1200.0, 'max': 4400.0}, {'current': 1200.098, 'min': 1200.0, 'max': 4400.0}, {'current': 1200.091, 'min': 1200.0, 'max': 4400.0}, {'current': 1288.153, 'min': 1200.0, 'max': 4400.0}, {'current': 1200.277, 'min': 1200.0, 'max': 4400.0}, {'current': 1200.235, 'min': 1200.0, 'max': 4400.0}, {'current': 1262.619, 'min': 1200.0, 'max': 4400.0}, {'current': 1200.434, 'min': 1200.0, 'max': 4500.0}, {'current': 1200.367, 'min': 1200.0, 'max': 4500.0}], 'disk': {'total': 1738.1651229858398, 'used': 1516.3677101135254}, 'gpu': 'NVIDIA GeForce RTX 2080 Ti', 'gpu_count': 4, 'gpu_devices': [{'name': 'NVIDIA GeForce RTX 2080 Ti', 'memory_total': 11811160064}, {'name': 'NVIDIA GeForce RTX 2080 Ti', 'memory_total': 11811160064}, {'name': 'NVIDIA GeForce RTX 2080 Ti', 'memory_total': 11811160064}, {'name': 'NVIDIA GeForce RTX 2080 Ti', 'memory_total': 11811160064}], 'memory': {'total': 93.98457717895508}}","{'allocatedmax': 38.0, 'allocatedmed': 38.0, 'allocatedgbmax': 18.14, 'allocatedgbmed': 17.89}"
5,"{'eval/prec': 0.9309090909090908, '_timestamp': 1700010351.414554, 'train/loss': 0.2473, 'eval/samples_per_second': 8.594, 'eval/steps_per_second': 1.074, 'eval/loss': 0.34022969007492065, 'train/epoch': 1.13, 'eval/runtime': 116.3654, 'train/global_step': 1090, '_step': 216, '_runtime': 16658.944844961166, 'eval/acc': 0.918, 'eval/f1_ma': 0.9018156912893754, 'eval/rec': 0.8025078369905956, 'eval/f1_bi': 0.8619528619528619, 'train/learning_rate': 4.3659043659043665e-06}","{'bf16': False, 'fp16': True, 'fsdp': [], 'seed': 42, 'tf32': None, 'debug': [], 'optim': 'adamw_torch', 'top_k': 50, 'top_p': 1, 'prefix': None, 'do_eval': True, 'no_cuda': False, 'use_cpu': False, 'do_train': False, 'id2label': {'0': 'LABEL_0', '1': 'LABEL_1'}, 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'run_name': './output-trainer', 'use_ipex': False, 'adafactor': False, 'data_seed': None, 'deepspeed': None, 'do_sample': False, 'hub_token': '<HUB_TOKEN>', 'log_level': 'passive', 'max_steps': -1, 'num_beams': 1, 'ray_scope': 'last', 'report_to': ['wandb'], 'typical_p': 1, 'use_cache': True, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'do_predict': False, 'eval_delay': 0, 'eval_steps': 10, 'hidden_act': 'silu', 'is_decoder': False, 'local_rank': 0, 'max_length': 20, 'min_length': 0, 'model_type': 'llama', 'optim_args': None, 'output_dir': './output-trainer', 'past_index': -1, 'rope_theta': 10000, 'save_steps': 100, 'vocab_size': 32000, 'ddp_backend': None, 'ddp_timeout': 1800, 'fsdp_config': {'xla': False, 'min_num_params': 0, 'xla_fsdp_grad_ckpt': False}, 'hidden_size': 4096, 'label_names': None, 'logging_dir': './output-trainer/logs', 'push_to_hub': False, 'return_dict': True, 'temperature': 1, 'torch_dtype': 'float16', 'torchdynamo': None, 'torchscript': False, 'adam_epsilon': 1e-08, 'bos_token_id': 1, 'disable_tqdm': False, 'eos_token_id': 2, 'fp16_backend': 'auto', 'hub_model_id': None, 'hub_strategy': 'every_save', 'pad_token_id': 2, 'problem_type': None, 'pruned_heads': {}, 'rms_norm_eps': 1e-05, 'rope_scaling': None, 'sep_token_id': None, 'use_bfloat16': False, 'warmup_ratio': 0, 'warmup_steps': 0, 'weight_decay': 0.01, 'architectures': ['LlamaForCausalLM'], 'bad_words_ids': None, 'jit_mode_eval': False, 'learning_rate': 1e-05, 'logging_steps': 10, 'max_grad_norm': 1, 'mp_parameters': '', 'output_scores': False, 'save_strategy': 'steps', 'split_batches': False, 'torch_compile': False, 'tpu_num_cores': None, 'attention_bias': False, 'bf16_full_eval': False, 'early_stopping': False, 'fp16_full_eval': False, 'fp16_opt_level': 'O1', 'length_penalty': 1, 'pretraining_tp': 1, 'tf_legacy_loss': False, 'use_mps_device': False, 'finetuning_task': None, 'group_by_length': False, 'hub_always_push': False, 'num_beam_groups': 1, 'suppress_tokens': None, 'tokenizer_class': None, 'deepspeed_plugin': None, 'dispatch_batches': None, 'full_determinism': False, 'hub_private_repo': False, 'ignore_data_skip': False, 'log_on_each_node': True, 'logging_strategy': 'steps', 'num_train_epochs': 2, 'save_safetensors': True, 'save_total_limit': 12, 'ddp_bucket_cap_mb': None, 'distributed_state': 'Distributed environment: NO\nNum processes: 1\nProcess index: 0\nLocal process index: 0\nDevice: cuda\n', 'diversity_penalty': 0, 'greater_is_better': True, 'initializer_range': 0.02, 'intermediate_size': 11008, 'log_level_replica': 'warning', 'lr_scheduler_type': 'linear', 'num_hidden_layers': 32, 'output_attentions': False, 'push_to_hub_token': '<PUSH_TO_HUB_TOKEN>', 'save_on_each_node': False, 'tpu_metrics_debug': False, 'is_encoder_decoder': False, 'length_column_name': 'length', 'logging_first_step': False, 'repetition_penalty': 1, 'torch_compile_mode': None, 'add_cross_attention': False, 'evaluation_strategy': 'steps', 'forced_bos_token_id': None, 'forced_eos_token_id': None, 'fsdp_min_num_params': 0, 'neftune_noise_alpha': None, 'num_attention_heads': 32, 'num_key_value_heads': 32, 'quantization_config': {'load_in_4bit': True, 'load_in_8bit': False, 'quant_method': 'QuantizationMethod.BITS_AND_BYTES', 'llm_int8_threshold': 6, 'bnb_4bit_quant_type': 'nf4', 'llm_int8_skip_modules': None, 'bnb_4bit_compute_dtype': 'bfloat16', 'llm_int8_has_fp16_weight': False, 'bnb_4bit_use_double_quant': True, 'llm_int8_enable_fp32_cpu_offload': False}, 'skip_memory_metrics': True, 'tie_encoder_decoder': False, 'tie_word_embeddings': False, 'auto_find_batch_size': False, 'dataloader_drop_last': False, 'no_repeat_ngram_size': 0, 'num_return_sequences': 1, 'output_hidden_states': False, 'overwrite_output_dir': True, 'prediction_loss_only': False, 'push_to_hub_model_id': None, 'task_specific_params': None, 'transformers_version': '4.35.0', 'begin_suppress_tokens': None, 'dataloader_pin_memory': True, 'ddp_broadcast_buffers': None, 'metric_for_best_model': 'f1_bi', 'remove_invalid_values': False, 'remove_unused_columns': True, 'torch_compile_backend': None, 'dataloader_num_workers': 0, 'decoder_start_token_id': None, 'gradient_checkpointing': False, 'half_precision_backend': 'auto', 'label_smoothing_factor': 0, 'load_best_model_at_end': True, 'logging_nan_inf_filter': True, 'resume_from_checkpoint': None, 'chunk_size_feed_forward': 0, 'eval_accumulation_steps': None, 'max_position_embeddings': 4096, 'per_gpu_eval_batch_size': None, 'return_dict_in_generate': False, 'per_gpu_train_batch_size': None, 'push_to_hub_organization': None, 'include_tokens_per_second': False, 'ddp_find_unused_parameters': None, 'include_inputs_for_metrics': False, 'per_device_eval_batch_size': 8, 'use_legacy_prediction_loop': False, 'cross_attention_hidden_size': None, 'gradient_accumulation_steps': 1, 'per_device_train_batch_size': 8, 'encoder_no_repeat_ngram_size': 0, 'gradient_checkpointing_kwargs': None, 'exponential_decay_length_penalty': None, 'fsdp_transformer_layer_cls_to_wrap': None}",llama7|adamw_torch 8 1e-05 f1_bi 2|r21|0,"{'os': 'Linux-5.10.0-26-cloud-amd64-x86_64-with-glibc2.31', 'python': '3.10.13', 'heartbeatAt': '2023-11-14T20:28:12.842231', 'startedAt': '2023-11-14T20:28:12.463718', 'docker': None, 'cuda': None, 'args': [], 'state': 'running', 'program': '/home/jupyter/clef23_eval/cp_train_template_llama.py', 'codePathLocal': 'cp_train_template_llama.py', 'codePath': 'cp_train_template_llama.py', 'git': {'remote': 'https://github.com/marcinsawinski/clef23_eval.git', 'commit': 'bee7b4af4222bd243f46e28d94ef71ead83b604f'}, 'email': 'marcin.sawinski@gmail.com', 'root': '/home/jupyter/clef23_eval', 'host': 'clef-l4-4', 'username': 'marcinsawinski', 'executable': '/opt/conda/bin/python', 'cpu_count': 24, 'cpu_count_logical': 48, 'cpu_freq': {'current': 2200.2179999999976, 'min': 0.0, 'max': 0.0}, 'cpu_freq_per_core': [{'current': 2200.218, 'min': 0.0, 'max': 0.0}, {'current': 2200.218, 'min': 0.0, 'max': 0.0}, {'current': 2200.218, 'min': 0.0, 'max': 0.0}, {'current': 2200.218, 'min': 0.0, 'max': 0.0}, {'current': 2200.218, 'min': 0.0, 'max': 0.0}, {'current': 2200.218, 'min': 0.0, 'max': 0.0}, {'current': 2200.218, 'min': 0.0, 'max': 0.0}, {'current': 2200.218, 'min': 0.0, 'max': 0.0}, {'current': 2200.218, 'min': 0.0, 'max': 0.0}, {'current': 2200.218, 'min': 0.0, 'max': 0.0}, {'current': 2200.218, 'min': 0.0, 'max': 0.0}, {'current': 2200.218, 'min': 0.0, 'max': 0.0}, {'current': 2200.218, 'min': 0.0, 'max': 0.0}, {'current': 2200.218, 'min': 0.0, 'max': 0.0}, {'current': 2200.218, 'min': 0.0, 'max': 0.0}, {'current': 2200.218, 'min': 0.0, 'max': 0.0}, {'current': 2200.218, 'min': 0.0, 'max': 0.0}, {'current': 2200.218, 'min': 0.0, 'max': 0.0}, {'current': 2200.218, 'min': 0.0, 'max': 0.0}, {'current': 2200.218, 'min': 0.0, 'max': 0.0}, {'current': 2200.218, 'min': 0.0, 'max': 0.0}, {'current': 2200.218, 'min': 0.0, 'max': 0.0}, {'current': 2200.218, 'min': 0.0, 'max': 0.0}, {'current': 2200.218, 'min': 0.0, 'max': 0.0}, {'current': 2200.218, 'min': 0.0, 'max': 0.0}, {'current': 2200.218, 'min': 0.0, 'max': 0.0}, {'current': 2200.218, 'min': 0.0, 'max': 0.0}, {'current': 2200.218, 'min': 0.0, 'max': 0.0}, {'current': 2200.218, 'min': 0.0, 'max': 0.0}, {'current': 2200.218, 'min': 0.0, 'max': 0.0}, {'current': 2200.218, 'min': 0.0, 'max': 0.0}, {'current': 2200.218, 'min': 0.0, 'max': 0.0}, {'current': 2200.218, 'min': 0.0, 'max': 0.0}, {'current': 2200.218, 'min': 0.0, 'max': 0.0}, {'current': 2200.218, 'min': 0.0, 'max': 0.0}, {'current': 2200.218, 'min': 0.0, 'max': 0.0}, {'current': 2200.218, 'min': 0.0, 'max': 0.0}, {'current': 2200.218, 'min': 0.0, 'max': 0.0}, {'current': 2200.218, 'min': 0.0, 'max': 0.0}, {'current': 2200.218, 'min': 0.0, 'max': 0.0}, {'current': 2200.218, 'min': 0.0, 'max': 0.0}, {'current': 2200.218, 'min': 0.0, 'max': 0.0}, {'current': 2200.218, 'min': 0.0, 'max': 0.0}, {'current': 2200.218, 'min': 0.0, 'max': 0.0}, {'current': 2200.218, 'min': 0.0, 'max': 0.0}, {'current': 2200.218, 'min': 0.0, 'max': 0.0}, {'current': 2200.218, 'min': 0.0, 'max': 0.0}, {'current': 2200.218, 'min': 0.0, 'max': 0.0}], 'disk': {'/': {'total': 147.40181350708008, 'used': 75.13926315307617}}, 'gpu': 'NVIDIA L4', 'gpu_count': 4, 'gpu_devices': [{'name': 'NVIDIA L4', 'memory_total': 24152899584}, {'name': 'NVIDIA L4', 'memory_total': 24152899584}, {'name': 'NVIDIA L4', 'memory_total': 24152899584}, {'name': 'NVIDIA L4', 'memory_total': 24152899584}], 'memory': {'total': 188.70611572265625}}","{'allocatedmax': 17.0, 'allocatedmed': 17.0, 'allocatedgbmax': 16.7, 'allocatedgbmed': 16.7}"
6,"{'eval/steps_per_second': 1.432, '_runtime': 13044.44738125801, 'eval/loss': 0.3281194269657135, 'train/global_step': 1100, 'eval/samples_per_second': 11.455, 'train/train_samples_per_second': 1.199, '_wandb': {'runtime': 13043}, 'dev_test_f1': 0.779, 'eval/runtime': 87.3016, 'test_precision': 0.899, 'train/learning_rate': 4.3087318087318095e-06, 'train/train_steps_per_second': 0.15, 'eval/prec': 0.9311594202898552, '_timestamp': 1700009663.9790154, 'test_recall': 0.741, '_step': 228, 'test_f1': 0.812, 'dev_test_precision': 0.926, 'eval/f1_ma': 0.903107150333443, 'train/train_loss': 0.4074977518211711, 'dev_test_accuracy': 0.81, 'eval/rec': 0.8056426332288401, 'train/epoch': 1.14, 'train/total_flos': 6.70609679081472e+16, 'train/train_runtime': 12834.5342, 'eval/f1_bi': 0.8638655462184874, 'train/loss': 0.142, 'test_accuracy': 0.884, 'eval/acc': 0.919, 'dev_test_recall': 0.673}","{'bf16': False, 'fp16': True, 'fsdp': [], 'seed': 42, 'tf32': None, 'debug': [], 'optim': 'adamw_torch', 'top_k': 50, 'top_p': 1, 'prefix': None, 'do_eval': True, 'no_cuda': False, 'use_cpu': False, 'do_train': False, 'id2label': {'0': 'LABEL_0', '1': 'LABEL_1'}, 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'run_name': './output-trainer', 'use_ipex': False, 'adafactor': False, 'data_seed': None, 'deepspeed': None, 'do_sample': False, 'hub_token': '<HUB_TOKEN>', 'log_level': 'passive', 'max_steps': -1, 'num_beams': 1, 'ray_scope': 'last', 'report_to': ['wandb'], 'typical_p': 1, 'use_cache': True, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'do_predict': False, 'eval_delay': 0, 'eval_steps': 10, 'hidden_act': 'silu', 'is_decoder': False, 'local_rank': 0, 'max_length': 20, 'min_length': 0, 'model_type': 'llama', 'optim_args': None, 'output_dir': './output-trainer', 'past_index': -1, 'rope_theta': 10000, 'save_steps': 100, 'vocab_size': 32000, 'ddp_backend': None, 'ddp_timeout': 1800, 'fsdp_config': {'xla': False, 'min_num_params': 0, 'xla_fsdp_grad_ckpt': False}, 'hidden_size': 4096, 'label_names': None, 'logging_dir': './output-trainer/logs', 'push_to_hub': False, 'return_dict': True, 'temperature': 1, 'torch_dtype': 'float16', 'torchdynamo': None, 'torchscript': False, 'adam_epsilon': 1e-08, 'bos_token_id': 1, 'disable_tqdm': False, 'eos_token_id': 2, 'fp16_backend': 'auto', 'hub_model_id': None, 'hub_strategy': 'every_save', 'pad_token_id': 2, 'problem_type': None, 'pruned_heads': {}, 'rms_norm_eps': 1e-05, 'rope_scaling': None, 'sep_token_id': None, 'use_bfloat16': False, 'warmup_ratio': 0, 'warmup_steps': 0, 'weight_decay': 0.01, 'architectures': ['LlamaForCausalLM'], 'bad_words_ids': None, 'jit_mode_eval': False, 'learning_rate': 1e-05, 'logging_steps': 10, 'max_grad_norm': 1, 'mp_parameters': '', 'output_scores': False, 'save_strategy': 'steps', 'split_batches': False, 'torch_compile': False, 'tpu_num_cores': None, 'attention_bias': False, 'bf16_full_eval': False, 'early_stopping': False, 'fp16_full_eval': False, 'fp16_opt_level': 'O1', 'length_penalty': 1, 'pretraining_tp': 1, 'tf_legacy_loss': False, 'use_mps_device': False, 'finetuning_task': None, 'group_by_length': False, 'hub_always_push': False, 'num_beam_groups': 1, 'suppress_tokens': None, 'tokenizer_class': None, 'deepspeed_plugin': None, 'dispatch_batches': None, 'full_determinism': False, 'hub_private_repo': False, 'ignore_data_skip': False, 'log_on_each_node': True, 'logging_strategy': 'steps', 'num_train_epochs': 2, 'save_safetensors': True, 'save_total_limit': 12, 'ddp_bucket_cap_mb': None, 'distributed_state': 'Distributed environment: NO\nNum processes: 1\nProcess index: 0\nLocal process index: 0\nDevice: cuda\n', 'diversity_penalty': 0, 'greater_is_better': True, 'initializer_range': 0.02, 'intermediate_size': 11008, 'log_level_replica': 'warning', 'lr_scheduler_type': 'linear', 'num_hidden_layers': 32, 'output_attentions': False, 'push_to_hub_token': '<PUSH_TO_HUB_TOKEN>', 'save_on_each_node': False, 'tpu_metrics_debug': False, 'is_encoder_decoder': False, 'length_column_name': 'length', 'logging_first_step': False, 'repetition_penalty': 1, 'torch_compile_mode': None, 'add_cross_attention': False, 'evaluation_strategy': 'steps', 'forced_bos_token_id': None, 'forced_eos_token_id': None, 'fsdp_min_num_params': 0, 'neftune_noise_alpha': None, 'num_attention_heads': 32, 'num_key_value_heads': 32, 'quantization_config': {'load_in_4bit': True, 'load_in_8bit': False, 'quant_method': 'QuantizationMethod.BITS_AND_BYTES', 'llm_int8_threshold': 6, 'bnb_4bit_quant_type': 'nf4', 'llm_int8_skip_modules': None, 'bnb_4bit_compute_dtype': 'bfloat16', 'llm_int8_has_fp16_weight': False, 'bnb_4bit_use_double_quant': True, 'llm_int8_enable_fp32_cpu_offload': False}, 'skip_memory_metrics': True, 'tie_encoder_decoder': False, 'tie_word_embeddings': False, 'auto_find_batch_size': False, 'dataloader_drop_last': False, 'no_repeat_ngram_size': 0, 'num_return_sequences': 1, 'output_hidden_states': False, 'overwrite_output_dir': True, 'prediction_loss_only': False, 'push_to_hub_model_id': None, 'task_specific_params': None, 'transformers_version': '4.35.0', 'begin_suppress_tokens': None, 'dataloader_pin_memory': True, 'ddp_broadcast_buffers': None, 'metric_for_best_model': 'f1_bi', 'remove_invalid_values': False, 'remove_unused_columns': True, 'torch_compile_backend': None, 'dataloader_num_workers': 0, 'decoder_start_token_id': None, 'gradient_checkpointing': False, 'half_precision_backend': 'auto', 'label_smoothing_factor': 0, 'load_best_model_at_end': True, 'logging_nan_inf_filter': True, 'resume_from_checkpoint': None, 'chunk_size_feed_forward': 0, 'eval_accumulation_steps': None, 'max_position_embeddings': 4096, 'per_gpu_eval_batch_size': None, 'return_dict_in_generate': False, 'per_gpu_train_batch_size': None, 'push_to_hub_organization': None, 'include_tokens_per_second': False, 'ddp_find_unused_parameters': None, 'include_inputs_for_metrics': False, 'per_device_eval_batch_size': 8, 'use_legacy_prediction_loop': False, 'cross_attention_hidden_size': None, 'gradient_accumulation_steps': 1, 'per_device_train_batch_size': 8, 'encoder_no_repeat_ngram_size': 0, 'gradient_checkpointing_kwargs': None, 'exponential_decay_length_penalty': None, 'fsdp_transformer_layer_cls_to_wrap': None}",llama7|adamw_torch 8 1e-05 f1_bi 2|r21|0,"{'os': 'Linux-5.10.0-21-amd64-x86_64-with-glibc2.29', 'python': '3.8.10', 'heartbeatAt': '2023-11-14T21:17:00.472272', 'startedAt': '2023-11-14T21:16:59.519262', 'docker': None, 'cuda': None, 'args': [], 'state': 'running', 'program': 'cp_train_template_llama.py', 'codePath': 'cp_train_template_llama.py', 'git': {'remote': 'https://github.com/marcinsawinski/clef23_eval.git', 'commit': '89a29553b86fd8d1ff71dfd9f51ed35477699a48'}, 'email': None, 'root': '/root/notebooks/msawinski/clef23_eval', 'host': 'c301b88b57d6', 'username': 'root', 'executable': '/usr/bin/python', 'cpu_count': 10, 'cpu_count_logical': 20, 'cpu_freq': {'current': 1204.7271, 'min': 1200.0, 'max': 4420.0}, 'cpu_freq_per_core': [{'current': 1199.676, 'min': 1200.0, 'max': 4400.0}, {'current': 1200.666, 'min': 1200.0, 'max': 4400.0}, {'current': 1200.525, 'min': 1200.0, 'max': 4400.0}, {'current': 1200.44, 'min': 1200.0, 'max': 4400.0}, {'current': 1200.22, 'min': 1200.0, 'max': 4400.0}, {'current': 1200.523, 'min': 1200.0, 'max': 4400.0}, {'current': 1200.319, 'min': 1200.0, 'max': 4400.0}, {'current': 1200.663, 'min': 1200.0, 'max': 4400.0}, {'current': 1200.0, 'min': 1200.0, 'max': 4500.0}, {'current': 1200.045, 'min': 1200.0, 'max': 4500.0}, {'current': 1199.999, 'min': 1200.0, 'max': 4400.0}, {'current': 1200.075, 'min': 1200.0, 'max': 4400.0}, {'current': 1200.493, 'min': 1200.0, 'max': 4400.0}, {'current': 1200.398, 'min': 1200.0, 'max': 4400.0}, {'current': 1200.366, 'min': 1200.0, 'max': 4400.0}, {'current': 1200.399, 'min': 1200.0, 'max': 4400.0}, {'current': 1200.342, 'min': 1200.0, 'max': 4400.0}, {'current': 1200.102, 'min': 1200.0, 'max': 4400.0}, {'current': 1200.457, 'min': 1200.0, 'max': 4500.0}, {'current': 1200.465, 'min': 1200.0, 'max': 4500.0}], 'disk': {'total': 1738.1651229858398, 'used': 1486.8977737426758}, 'gpu': 'NVIDIA GeForce RTX 2080 Ti', 'gpu_count': 4, 'gpu_devices': [{'name': 'NVIDIA GeForce RTX 2080 Ti', 'memory_total': 11811160064}, {'name': 'NVIDIA GeForce RTX 2080 Ti', 'memory_total': 11811160064}, {'name': 'NVIDIA GeForce RTX 2080 Ti', 'memory_total': 11811160064}, {'name': 'NVIDIA GeForce RTX 2080 Ti', 'memory_total': 11811160064}], 'memory': {'total': 93.98457717895508}}","{'allocatedmax': 26.0, 'allocatedmed': 26.0, 'allocatedgbmax': 12.31, 'allocatedgbmed': 12.15}"
